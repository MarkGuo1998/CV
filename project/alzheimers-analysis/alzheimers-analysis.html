<!DOCTYPE html>

<html>
<head>
    <link rel="stylesheet" type="text/css" href="../../CSS/main.css">
	<title>Graph-based Alzheimer's Disease Analysis with PET images</title>
	<meta charset="utf-8">
    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      <!--$表示行内元素，$$表示块状元素 -->
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>
<!--加载MathJax的最新文件， async表示异步加载进来 -->
<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js">
</script>
</head>
<body>
    <div>
        <h1>Graph-based MCI/NC Analysis with PET images</h1>
    </div>
    <div class="box">
        <p1><b>Framework</b></p1>
        <hr class="style-two">
    </div>
    <div>
        <span class="text" style="text-indent:2em">We used the Graph Convolutional Network (ChebNet) from <a href="http://papers.nips.cc/paper/6081-convolutional-neural-networks-on-graphs-with-fast-localized-spectral-filtering.pdf" target="_blank"><b>Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering</b></a>, NIPS 16', Michaël Defferrard et al. The original code can be found at this <a href="https://github.com/xbresson/spectral_graph_convnets" target="_blank"><b>link</b></a>.</span>
    </div>
    <br/>
    <div class="box">
        <p1><b>Data Description and Objective</b></p1>
        <hr class="style-two">
    </div>
    <div class="box">
        <span class="text" style="text-indent:2em"> We used <b>ADNI2-AV45 PET image</b> dataset with 419 subjects in total. The PET images are of 2mm-resolution and the shape is (91, 109, 91). There is only one image for a single subject with an associated label: <b>AD</b> (<i>Alzheimer's Disease</i>), <b>LMCI</b> (<i>Late Mild Cognitive Impairment</i>), <b>EMCI</b> (<i>Early MCI</i>) or <b>NC</b> (<i>Normal Control</i>).</span>
        <span class="text" style="text-indent:2em">Since current diagnosis of MCI is done through various types of assessment tests, <b>we intend to find a intrinsic diagnosis standard for MCI patients from both the brain structural / functional connection network and brain region signals instead</b>. By the analysis of PET-based brain network we can find the changes of volume and signal in which regions have the most severe influence on the process of MCI, and thus provide a better insight for the prevention of MCI and also more accurate diagnosis for the severe disease. </span>
    </div>
    <br/>
    <div class="box">
        <p1><b>Method and Contribution</b></p1>
        <hr class="style-two">
    </div>
    <div class="box">
        <span class="text"><i>Graph Construction</i> </span>
        <span class="text"></span>
        <span class="text" style="text-indent:2em"> We did not use the <b>k-NN</b> graph as the original paper, as that could make the network focus only on local features rather than global connections.</span> 
        <span class="text" style="text-indent:2em">Our method is listed as follows:</span> 
        <ul>
            <li> Extract 120-D signals from AAL-2 atlas (120 brain regions) in PET images, and put region signals from all subjects together to construct a data matrix of shape (120, 419); </li>
            <li type=none> <img src="120region-data.jpg" width=70% alt="region extraction"></li>
            <li> Compute correlation of the 120 regions, and use the correlation matrix as the <b>adjacency matrix</b> with a cut-off on entries at threshold 0.7; </li>
            <li type=none> <img src="120-graph.jpg" width=50% alt="region extraction"></li>
        </ul>
    </div>
    <div class="box">
        <span class="text"><i>Network Structure</i> </span>
        <span class="text"></span>
        <span class="text" style="text-indent:2em"> Notations for network architectures: </span>
        <ul>
            <li>FC<i>k</i> for a Fully Connected Layer with <i>k</i> hidden units;</li>
            <li>P<i>k</i> for a Graph Pooling Layer of size and stride <i>k</i>;</li>
            <li>GC<i>k</i> for a graph convolutional layer with <i>k</i> feature maps.</li>
        </ul>
        <span class="text" style="text-indent:2em">With $x$ as the input signal, $T_k$ as the (<i>k</i>-th) Chebyshev Polynomial, $L$ as the graph Laplacian, $K$ as the number of the kernels, and $\theta$ as the network parameter, the GC layer is fomulated by this equation: </span>
        $$G_L(x; \theta)=\sum_{k=0}^{K-1}\theta_kT_k(L)x.$$
        <span class="text" style="text-indent:2em"> All FC<i>k</i> and GC<i>k</i> layers are followed by a <b>Leaky</b>ReLU activation with $\alpha=0.01$.</span>
        <span class="text" style="text-indent:2em"> The final layer is a softmax regression and the loss energy E is the cross-entropy with an <i>l2</i> regularization on the weights of all FC<i>k</i> layers. Mini-batches are of size S = 20.</span>
        <span class="text" style="text-indent:2em"> Our final network structure is denoted by GC<i>32</i>-P<i>4</i>-GC<i>64</i>-P<i>4</i>-FC<i>512</i> with kernel number $K=25$ at each conv layer.</span> 
    </div>
    <br/>
    <div class="box">
        <span class="text"><i>Advantages of Our Graph-based Methods</i> </span>
        <ul>
            <li>Graph-based methods are more <b>robust</b> than image-based ones, because they use the region-level average signals rather than the voxel-level signals (in image-based methods), which could lead to instability when images are noisy on voxl-level;</li>
            <li>Incorporating <b>any</b> graph (even a randomly-generated graph with the same number of edges as the correlation graph) as a part of input almost <b>guarantees</b> a slight boosting in performance (compared with XGBoost);</li>
            <li>With our correlation graph as the input, the ChebNet yields the highest average classification accuracy (~93%) among all region-based experiments. The network performance with correlation graph is also much stabler than with random graphs.</li>
        </ul>
    </div>
    <div class="box">
        <p1><b>Experiments and Results</b></p1>
        <hr class="style-two">
    </div>
    <div class="box">
        <span class="text"><i>Experimental Settings</i> </span>
        <ul>
            <li>We randomly split the original dataset for 70% training and 30% test.</li>
            <li>To prevent "Dead ReLU" problem, we not only shrink the learning rate to $10^{-3}$, but also use a "LeakyReLU" activation function instead of the original "ReLU".</li>
            <li>The initial learning rate decays by 50% every time the training loss decreases by 50%, and this shrinkage operation has a cooldown of 150 epochs.</li>
            <li>We train the model for 1000 epochs in total.</li>
            <li>The l2 regularization coefficient is $10^{-4}$. </li>
        </ul>
    </div>
    <div class="box">
        <span class="text"><i>Results</i> </span>
        <ul>
            <li>93% accuracy (on average).</li>
            <li type=none> <img src="120-result.png" width=50% alt="region extraction"></li>
        </ul>
    </div>
    <div class="box">
        <span class="text"><i>Graph-based baselines</i> </span>
        <ul>
            <li>If we let $L=0$ (i.e. a graph with only self-loops), the Chebyshev convolutional layer degrades to a fully-connected layer ($G_0(x; \theta)=\sum_{k=0}^{K-1}\theta_kT_k(L)x=\theta_0x$). </li>
            <li type=none style="padding-left:2em; padding-right:2em">Thus the classification result is guaranteed to be better than FCN since we add some extra information into the classification process whenever $L\ne0$.</li>
            <li>To compare our construction of correlation graph with other graphs, we conducted extra experiments on the same training/test datasets.</li>
            <li>Empty Graph (with only self-loops)</li>
            <li type=none style="padding-left:2em; padding-right:2em">Below (<b>left</b>) is an example for empty graph (90% acc. with very unstable performance and very slow training speed.) </li>
            <li type=none style="padding-left:2em; padding-right:2em">When switching to correlation graph (<b>right</b>), the accuracy is about 92%. </li>
            <li type=none style="padding-left:2em; padding-right:2em">Overall, we not only have a (close, but still) better accuracy in correlation group, but also a much shorter convergence time (400 epochs versus ~1000 epochs). Considering that the connected correlation graph accelerates training process for another 2x (per epoch), the correlation method is significantly better than empty graph (i.e. fully connected layers). </li>
            <li type=none><img src="3-5-random.png" width=40% alt="random-graph-result"><img src="3-5-corr.png" width=40% alt="random-graph-result"></li>
            <li>Random Graph (with the same number of edges as the corralation graph with threshold=0.7)</li>
            <li type=none style="padding-left:2em; padding-right:2em">The result is 89% on average, but of much <b>larger variance</b>. Besides, on 90% of the experiments the random-graph ChebNet yields lower accuracy than the correlation-graph ChebNet <b>on the same training/test dataset.</b> </li>
            <li type=none style="padding-left:2em; padding-right:2em">Below are two examples for random graphs: </li>
            <li type=none><img src="120-random.png" width=40% alt="random-graph-result"><img src="120-2-random.png" width=40% alt="random-graph-result"></li>
        </ul>
    </div>
    <div class="box">
        <span class="text"><i>Region-based baselines</i> </span>
        <ul>
            <li>XGBoost Classifier: 88% on average (5-fold).</li>
        </ul>
    </div>
    <div class="box">
        <span class="text"><i>Image-based baselines</i> </span>
        <ul>
            <li>We extracted the 22nd, 45th and 67th slices from the original (91, 109, 91) 3D PET images and used them as the RGB channels respectively. We resized the slices to (299, 299) and use them as the input to some Convolutional Neural Network(CNN)s. </li>
            <li type=none style="padding-left:2em; padding-right:2em">The training process is either fine-tuning (if the network is initialized from pretrained weights on ImageNet) or simple training (if the network is randomly initialized). </li>
            <li> Results:</li>
            <li type=none style="padding-left:2em; padding-right:2em">Non-pretrained Inception-V3 / ResNet-50: 83% accuracy on average.</li>
            <li type=none style="padding-left:2em; padding-right:2em">Pretrained Inception-V3: 96+/-1%.</li>
        </ul>
    </div>
    <div class="box">
        <p1><b> Discussion </b></p1>
        <hr class="style-two">
    </div>
    <div class="box">
        <span class="text"><i>More experiments in image-based methods</i> </span>
        <ul>
            <li>In the <i>power atlas</i> experiment, there are some regions whose signals all equal to <i>zero</i> in MCI group but are all non-zero in NC groups. We are not sure if they have a serious impact on image-based experiment. </li>
            <li>We plan to add a noise on the images, which may damage the performance of image-based methods but have minor impact on graph-based experiments.</li>
        </ul>
    </div>
    <div class="box">
        <span class="text"><i>Feature importance of graph-based experiments</i> </span>
        <ul>
            <li> How will we analyze the feature importance of graph neural networks? The convolutional layer itself is another version of fully-connected layer with weight limited in a narrower vector space ($y=\text{LeakyRelu}(g_{\theta}(L)x)$). I'm not quite sure how to analyze it.</li>
            <li>I sent an e-mail to the author of ChebNet and hope to discuss the issue with him.</li>
        </ul>
    </div>   
</body>
</html>
